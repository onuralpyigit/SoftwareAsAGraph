{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project_name = \".\"\n",
    "project_name = \"jfreechart\"\n",
    "#project_name = \"argouml\"\n",
    "#project_name = \"kafka\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QualifiedName                 Name  Complexity   \n",
      "2           org.jfree.chart.ChartColor           ChartColor           2  \\\n",
      "3         org.jfree.chart.ChartElement         ChartElement           1   \n",
      "4  org.jfree.chart.ChartElementVisitor  ChartElementVisitor           1   \n",
      "5         org.jfree.chart.ChartFactory         ChartFactory           5   \n",
      "6           org.jfree.chart.ChartHints           ChartHints           1   \n",
      "\n",
      "   Coupling  Size  Lack of Cohesion   CBO    RFC  SRFC  DIT  ...  NOF  NOSF   \n",
      "2         1     2                 1   0.0    2.0   0.0  2.0  ...  0.0  24.0  \\\n",
      "3         1     1                 1   1.0    1.0   0.0  1.0  ...  0.0   0.0   \n",
      "4         1     1                 1   1.0    1.0   0.0  1.0  ...  0.0   0.0   \n",
      "5         5     3                 3  81.0  232.0  84.0  1.0  ...  0.0   1.0   \n",
      "6         1     1                 1   0.0    1.0   0.0  1.0  ...  0.0   2.0   \n",
      "\n",
      "   NOM  NOSM  NORM  LCOM   LCAM   LTCC  ATFD   SI  \n",
      "2  1.0   1.0   0.0   0.0  0.250  1.000   0.0  0.0  \n",
      "3  1.0   0.0   0.0   0.0  0.000  0.000   0.0  0.0  \n",
      "4  1.0   0.0   0.0   0.0  0.000  0.000   0.0  0.0  \n",
      "5  0.0  50.0   0.0   0.0  0.799  0.569   3.0  0.0  \n",
      "6  1.0   0.0   0.0   0.0  0.000  0.000   0.0  0.0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path, sep='\\t')\n",
    "    return data\n",
    "\n",
    "def remove_empty_rows(data):\n",
    "    data = data.dropna(subset=['Name'])\n",
    "    return data\n",
    "\n",
    "def remove_unnamed_columns(data):\n",
    "    data = data.filter(regex='^(?!Unnamed.*)')\n",
    "    return data\n",
    "\n",
    "def remove_nan_columns(data):\n",
    "    data = data.dropna(axis=1, how='all')\n",
    "    return data\n",
    "\n",
    "def remove_package_rows(data):\n",
    "    data = data[~data['QualifiedName'].str.contains(\"<Package>\")]\n",
    "    return data\n",
    "\n",
    "def convert_ordinal_to_numerical(data):\n",
    "    ordinal_mapping = {\n",
    "        'low': 1,\n",
    "        'low-medium': 2,\n",
    "        'medium-high': 3,\n",
    "        'high': 4,\n",
    "        'very-high': 5\n",
    "    }\n",
    "    columns_to_convert = ['Complexity', 'Coupling', 'Size', 'Lack of Cohesion']\n",
    "    for column in columns_to_convert:\n",
    "        data[column] = data[column].replace(ordinal_mapping)\n",
    "    return data\n",
    "\n",
    "dataset_file = \"input/\" + project_name + \"/class-metrics-dataset.csv\"\n",
    "dataset = load_data(dataset_file)\n",
    "dataset = remove_empty_rows(dataset)\n",
    "dataset = remove_unnamed_columns(dataset)\n",
    "dataset = remove_nan_columns(dataset)\n",
    "dataset = remove_package_rows(dataset)\n",
    "dataset = convert_ordinal_to_numerical(dataset)\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in the dataset: 633\n",
      "Number of Problematic Classes in the dataset: 84\n",
      "Number of Highly Problematic Classes in the dataset: 87\n"
     ]
    }
   ],
   "source": [
    "def label_problematic_class(row, problematic_class_threshold=2, highly_problematic_class_threshold=3):\n",
    "    problematic_score = (row['Complexity'] + row['Coupling'] + row['Size'] + row['Lack of Cohesion']) / 4\n",
    "    if problematic_score > highly_problematic_class_threshold:\n",
    "        return 2\n",
    "    elif problematic_score > problematic_class_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Label the dataset\n",
    "dataset['Problematic'] = dataset.apply(label_problematic_class, axis=1)\n",
    "\n",
    "# Count the number of Problematic Classes\n",
    "num_dataset_rows = dataset.shape[0]\n",
    "num_problematic_classes = dataset[dataset['Problematic'] == 1].shape[0]\n",
    "num_highly_problematic_classes = dataset[dataset['Problematic'] == 2].shape[0]\n",
    "print(f'Number of instances in the dataset: {num_dataset_rows}')\n",
    "print(f'Number of Problematic Classes in the dataset: {num_problematic_classes}')\n",
    "print(f'Number of Highly Problematic Classes in the dataset: {num_highly_problematic_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QualifiedName   CBO    RFC  SRFC  DIT  NOC    WMC   \n",
      "2           org.jfree.chart.ChartColor   0.0    2.0   0.0  2.0  0.0    2.0  \\\n",
      "3         org.jfree.chart.ChartElement   1.0    1.0   0.0  1.0  7.0    1.0   \n",
      "4  org.jfree.chart.ChartElementVisitor   1.0    1.0   0.0  1.0  0.0    1.0   \n",
      "5         org.jfree.chart.ChartFactory  81.0  232.0  84.0  1.0  0.0  137.0   \n",
      "6           org.jfree.chart.ChartHints   0.0    1.0   0.0  1.0  0.0    1.0   \n",
      "\n",
      "     LOC  CMLOC  NOF  NOSF  NOM  NOSM  NORM  LCOM   LCAM   LTCC  ATFD   SI   \n",
      "2   64.0   39.0  0.0  24.0  1.0   1.0   0.0   0.0  0.250  1.000   0.0  0.0  \\\n",
      "3    2.0    1.0  0.0   0.0  1.0   0.0   0.0   0.0  0.000  0.000   0.0  0.0   \n",
      "4    2.0    1.0  0.0   0.0  1.0   0.0   0.0   0.0  0.000  0.000   0.0  0.0   \n",
      "5  782.0  780.0  0.0   1.0  0.0  50.0   0.0   0.0  0.799  0.569   3.0  0.0   \n",
      "6   17.0    1.0  0.0   2.0  1.0   0.0   0.0   0.0  0.000  0.000   0.0  0.0   \n",
      "\n",
      "   Problematic  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "5            2  \n",
      "6            0  \n"
     ]
    }
   ],
   "source": [
    "def remove_labeling_columns(data):\n",
    "    data = data.drop(['Name', 'Complexity', 'Coupling', 'Size', 'Lack of Cohesion'], axis=1)\n",
    "    return data\n",
    "\n",
    "dataset = remove_labeling_columns(dataset)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    X = data.drop(['QualifiedName', 'Problematic'], axis=1)\n",
    "    y = data['Problematic']\n",
    "    return X, y\n",
    "\n",
    "X, y = preprocess_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_decision_tree(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf, X_test, y_test\n",
    "\n",
    "clf, X_test, y_test = train_decision_tree(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(clf, X_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "y_pred = make_predictions(clf, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[122   9   0]\n",
      " [  4  19   1]\n",
      " [  1   1  33]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       131\n",
      "           1       0.66      0.79      0.72        24\n",
      "           2       0.97      0.94      0.96        35\n",
      "\n",
      "    accuracy                           0.92       190\n",
      "   macro avg       0.86      0.89      0.87       190\n",
      "weighted avg       0.92      0.92      0.92       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_results(y_test, y_pred):\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "evaluate_results(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
